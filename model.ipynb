{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd34dc7f-067c-4ad6-bc01-f6eb1f2fb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation,Dropout, LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6844fb-dd61-40c3-8754-b9827844bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/wojtek/Desktop/emotion_recognition/dataset/internet_dataset/final_dataset_v8_top_3000_spellchecked.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251bc12e-2b20-447d-91e5-00fa48ee36d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happiness</td>\n",
       "      <td>period fall love time meet especially not meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>involve traffic accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>drive home several day hard work motorist ahea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>lose person meant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>time knock deer sight animal injury helplessne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion                                            comment\n",
       "0  happiness  period fall love time meet especially not meet...\n",
       "1       fear                           involve traffic accident\n",
       "2      anger  drive home several day hard work motorist ahea...\n",
       "3    sadness                                  lose person meant\n",
       "4    disgust  time knock deer sight animal injury helplessne..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40305480-0d57-4725-97da-00b62df1701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment']\n",
    "y = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2f7ca7-8a33-4c3a-b118-705dcdb04679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happiness    3000\n",
       "fear         3000\n",
       "anger        3000\n",
       "sadness      3000\n",
       "disgust      3000\n",
       "surprise     2999\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385f0ead-c824-4e39-a885-9db97654b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['comment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72b95707-d5eb-4ea1-8d1f-fee0e8ef2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcfb3967-4e2e-4cd9-89d8-d2e2192c2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(token.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28a4b967-2052-4dca-9b75-b6dd26ce4da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19097"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f75aa83-37f3-45c0-b94c-d183f15f23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979f0906-8fd7-47c7-9d56-98e5b97cb4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[814, 360, 30, 10, 122, 529, 1, 122, 82, 10],\n",
       " [678, 896, 320],\n",
       " [216,\n",
       "  31,\n",
       "  306,\n",
       "  6,\n",
       "  175,\n",
       "  15,\n",
       "  9237,\n",
       "  963,\n",
       "  216,\n",
       "  269,\n",
       "  126,\n",
       "  399,\n",
       "  633,\n",
       "  447,\n",
       "  1442,\n",
       "  93,\n",
       "  2760]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = token.texts_to_sequences(text)\n",
    "encoded_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbf0e94e-06c7-450a-91c3-771889fb747f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  814,   360,    30, ...,     0,     0,     0],\n",
       "       [  678,   896,   320, ...,     0,     0,     0],\n",
       "       [  216,    31,   306, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [19096,    20,   395, ...,     0,     0,     0],\n",
       "       [  192,  1144,    73, ...,     0,     0,     0],\n",
       "       [  100,   509,  3340, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 120 # machine learning potrzebuje żeby zdania były max sized (pewnie pozostałe to 0)\n",
    "X = pad_sequences(encoded_text, maxlen=max_length, padding='post') # padding post po to, by 0 byly dodane na koncu listy\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df797cb2-f6b7-457e-819d-cec3ec3060b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17999, 120)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "728ecb95-3fd3-48e7-81bd-8c742facebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###`GloVe` Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96a812c5-7775-4f4c-91dc-c876ceaf3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = \"/home/wojtek/Desktop/glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35968714-fcb9-4e57-adde-e297193cfc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87b1d85e-33a8-4d5b-b97d-218eb897dcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.06 s, sys: 3.05 s, total: 9.11 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(path_to_glove_file) as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vectors = np.asarray(values[1:])  # list will be converted as array\n",
    "        glove_vectors[word] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5634c44e-d8a2-4001-8e44-bc7275c25223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "002a6cea-9648-4a85-8263-44f1a065b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.get('you').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c6b5868-dac8-4385-97b9-68e7d746103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_matrix = np.zeros((vocab_size, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2814818e-c558-4665-a5a6-d44ba81d4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in token.word_index.items():\n",
    "    vector = glove_vectors.get(word)\n",
    "    if vector is not None:\n",
    "        word_vector_matrix[index] = vector\n",
    "    # else:\n",
    "        # print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eefa34e5-8c91-4922-baf5-10ce365896b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TF2.0 and Keras Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54381fb8-426d-4bc1-9deb-baa72d2c9487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  814,   360,    30, ...,     0,     0,     0],\n",
       "       [  678,   896,   320, ...,     0,     0,     0],\n",
       "       [  216,    31,   306, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [19096,    20,   395, ...,     0,     0,     0],\n",
       "       [  192,  1144,    73, ...,     0,     0,     0],\n",
       "       [  100,   509,  3340, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "063bb5f9-a30c-4d4a-a526-41a8cb20e9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        happiness\n",
       "1             fear\n",
       "2            anger\n",
       "3          sadness\n",
       "4          disgust\n",
       "           ...    \n",
       "17994     surprise\n",
       "17995     surprise\n",
       "17996     surprise\n",
       "17997     surprise\n",
       "17998     surprise\n",
       "Name: emotion, Length: 17999, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20c0f118-1f3e-4953-b8c0-060948e866a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7948ec57-cc80-41df-8b32-a911fab2a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_label = le.fit_transform(y)\n",
    "y_label = to_categorical(y_label, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfbfc3da-d790-4a36-972a-8ea4829e0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_label, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caef4eae-f228-4d43-a0e2-6291b8278e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14399, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63ab3e70-0e66-48c4-8a13-c6943215537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14399, 120)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66f565e7-3d27-4ea9-862f-a253923ecc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60d09d85-9a0d-47f2-b6f4-5e5937efb447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 1.8111 - accuracy: 0.2022 - val_loss: 1.7356 - val_accuracy: 0.2581\n",
      "Epoch 2/60\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 1.7141 - accuracy: 0.2466 - val_loss: 1.6662 - val_accuracy: 0.3119\n",
      "Epoch 3/60\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 1.6499 - accuracy: 0.2770 - val_loss: 1.5937 - val_accuracy: 0.3506\n",
      "Epoch 4/60\n",
      "1200/1200 [==============================] - 28s 23ms/step - loss: 1.5990 - accuracy: 0.3066 - val_loss: 1.5366 - val_accuracy: 0.3853\n",
      "Epoch 5/60\n",
      "1200/1200 [==============================] - 26s 22ms/step - loss: 1.5560 - accuracy: 0.3275 - val_loss: 1.5029 - val_accuracy: 0.4231\n",
      "Epoch 6/60\n",
      "1200/1200 [==============================] - 25s 20ms/step - loss: 1.5183 - accuracy: 0.3636 - val_loss: 1.4579 - val_accuracy: 0.4425\n",
      "Epoch 7/60\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: 1.4849 - accuracy: 0.3756 - val_loss: 1.4107 - val_accuracy: 0.4642\n",
      "Epoch 8/60\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 1.4545 - accuracy: 0.3959 - val_loss: 1.3783 - val_accuracy: 0.4747\n",
      "Epoch 9/60\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: 1.4289 - accuracy: 0.4145 - val_loss: 1.3478 - val_accuracy: 0.4889\n",
      "Epoch 10/60\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 1.3913 - accuracy: 0.4341 - val_loss: 1.3194 - val_accuracy: 0.4969\n",
      "Epoch 11/60\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 1.3632 - accuracy: 0.4503 - val_loss: 1.2920 - val_accuracy: 0.5058\n",
      "Epoch 12/60\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 1.3472 - accuracy: 0.4608 - val_loss: 1.2649 - val_accuracy: 0.5258\n",
      "Epoch 13/60\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 1.3263 - accuracy: 0.4642 - val_loss: 1.2498 - val_accuracy: 0.5181\n",
      "Epoch 14/60\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 1.2991 - accuracy: 0.4785 - val_loss: 1.2318 - val_accuracy: 0.5278\n",
      "Epoch 15/60\n",
      "1200/1200 [==============================] - 25s 20ms/step - loss: 1.2817 - accuracy: 0.4855 - val_loss: 1.2115 - val_accuracy: 0.5325\n",
      "Epoch 16/60\n",
      "1200/1200 [==============================] - 31s 26ms/step - loss: 1.2653 - accuracy: 0.5000 - val_loss: 1.1997 - val_accuracy: 0.5372\n",
      "Epoch 17/60\n",
      "1200/1200 [==============================] - 46s 38ms/step - loss: 1.2450 - accuracy: 0.5037 - val_loss: 1.1851 - val_accuracy: 0.5417\n",
      "Epoch 18/60\n",
      "1200/1200 [==============================] - 46s 39ms/step - loss: 1.2261 - accuracy: 0.5149 - val_loss: 1.1794 - val_accuracy: 0.5492\n",
      "Epoch 19/60\n",
      "1200/1200 [==============================] - 45s 37ms/step - loss: 1.2152 - accuracy: 0.5218 - val_loss: 1.1665 - val_accuracy: 0.5458\n",
      "Epoch 20/60\n",
      "1200/1200 [==============================] - 45s 37ms/step - loss: 1.1991 - accuracy: 0.5256 - val_loss: 1.1540 - val_accuracy: 0.5533\n",
      "Epoch 21/60\n",
      "1200/1200 [==============================] - 49s 41ms/step - loss: 1.1856 - accuracy: 0.5294 - val_loss: 1.1482 - val_accuracy: 0.5503\n",
      "Epoch 22/60\n",
      "1200/1200 [==============================] - 45s 38ms/step - loss: 1.1677 - accuracy: 0.5348 - val_loss: 1.1420 - val_accuracy: 0.5539\n",
      "Epoch 23/60\n",
      "1200/1200 [==============================] - 45s 37ms/step - loss: 1.1610 - accuracy: 0.5426 - val_loss: 1.1361 - val_accuracy: 0.5561\n",
      "Epoch 24/60\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 1.1483 - accuracy: 0.5433 - val_loss: 1.1311 - val_accuracy: 0.5608\n",
      "Epoch 25/60\n",
      "1200/1200 [==============================] - 46s 39ms/step - loss: 1.1381 - accuracy: 0.5526 - val_loss: 1.1266 - val_accuracy: 0.5608\n",
      "Epoch 26/60\n",
      "1200/1200 [==============================] - 46s 39ms/step - loss: 1.1333 - accuracy: 0.5530 - val_loss: 1.1199 - val_accuracy: 0.5569\n",
      "Epoch 27/60\n",
      "1200/1200 [==============================] - 46s 38ms/step - loss: 1.1184 - accuracy: 0.5596 - val_loss: 1.1178 - val_accuracy: 0.5586\n",
      "Epoch 28/60\n",
      "1200/1200 [==============================] - 48s 40ms/step - loss: 1.1111 - accuracy: 0.5621 - val_loss: 1.1181 - val_accuracy: 0.5597\n",
      "Epoch 29/60\n",
      "1200/1200 [==============================] - 53s 44ms/step - loss: 1.1081 - accuracy: 0.5680 - val_loss: 1.1077 - val_accuracy: 0.5681\n",
      "Epoch 30/60\n",
      "1200/1200 [==============================] - 66s 55ms/step - loss: 1.0953 - accuracy: 0.5756 - val_loss: 1.1108 - val_accuracy: 0.5656\n",
      "Epoch 31/60\n",
      "1200/1200 [==============================] - 53s 44ms/step - loss: 1.0886 - accuracy: 0.5741 - val_loss: 1.1064 - val_accuracy: 0.5742\n",
      "Epoch 32/60\n",
      "1200/1200 [==============================] - 50s 42ms/step - loss: 1.0770 - accuracy: 0.5782 - val_loss: 1.1053 - val_accuracy: 0.5692\n",
      "Epoch 33/60\n",
      "1200/1200 [==============================] - 47s 39ms/step - loss: 1.0738 - accuracy: 0.5839 - val_loss: 1.1003 - val_accuracy: 0.5728\n",
      "Epoch 34/60\n",
      "1200/1200 [==============================] - 84s 70ms/step - loss: 1.0618 - accuracy: 0.5906 - val_loss: 1.0981 - val_accuracy: 0.5714\n",
      "Epoch 35/60\n",
      "1200/1200 [==============================] - 85s 70ms/step - loss: 1.0567 - accuracy: 0.5873 - val_loss: 1.0968 - val_accuracy: 0.5681\n",
      "Epoch 36/60\n",
      "1200/1200 [==============================] - 84s 70ms/step - loss: 1.0519 - accuracy: 0.5887 - val_loss: 1.0962 - val_accuracy: 0.5711\n",
      "Epoch 37/60\n",
      "1200/1200 [==============================] - 83s 69ms/step - loss: 1.0403 - accuracy: 0.5900 - val_loss: 1.0952 - val_accuracy: 0.5733\n",
      "Epoch 38/60\n",
      "1200/1200 [==============================] - 87s 73ms/step - loss: 1.0307 - accuracy: 0.5979 - val_loss: 1.0911 - val_accuracy: 0.5650\n",
      "Epoch 39/60\n",
      "1200/1200 [==============================] - 86s 72ms/step - loss: 1.0200 - accuracy: 0.6007 - val_loss: 1.0921 - val_accuracy: 0.5719\n",
      "Epoch 40/60\n",
      "1200/1200 [==============================] - 85s 71ms/step - loss: 1.0246 - accuracy: 0.5994 - val_loss: 1.0921 - val_accuracy: 0.5678\n",
      "Epoch 41/60\n",
      "1200/1200 [==============================] - 85s 70ms/step - loss: 1.0092 - accuracy: 0.6092 - val_loss: 1.0898 - val_accuracy: 0.5722\n",
      "Epoch 42/60\n",
      "1200/1200 [==============================] - 97s 81ms/step - loss: 1.0052 - accuracy: 0.6107 - val_loss: 1.0907 - val_accuracy: 0.5706\n",
      "Epoch 43/60\n",
      "1200/1200 [==============================] - 85s 71ms/step - loss: 0.9947 - accuracy: 0.6158 - val_loss: 1.0874 - val_accuracy: 0.5786\n",
      "Epoch 44/60\n",
      "1200/1200 [==============================] - 64s 53ms/step - loss: 0.9960 - accuracy: 0.6075 - val_loss: 1.0914 - val_accuracy: 0.5697\n",
      "Epoch 45/60\n",
      "1200/1200 [==============================] - 58s 49ms/step - loss: 0.9891 - accuracy: 0.6147 - val_loss: 1.0899 - val_accuracy: 0.5764\n",
      "Epoch 46/60\n",
      "1200/1200 [==============================] - 58s 48ms/step - loss: 0.9764 - accuracy: 0.6213 - val_loss: 1.0926 - val_accuracy: 0.5739\n",
      "Epoch 47/60\n",
      "1200/1200 [==============================] - 59s 49ms/step - loss: 0.9768 - accuracy: 0.6221 - val_loss: 1.0864 - val_accuracy: 0.5814\n",
      "Epoch 48/60\n",
      "1200/1200 [==============================] - 58s 49ms/step - loss: 0.9611 - accuracy: 0.6278 - val_loss: 1.0872 - val_accuracy: 0.5775\n",
      "Epoch 49/60\n",
      "1200/1200 [==============================] - 61s 50ms/step - loss: 0.9578 - accuracy: 0.6289 - val_loss: 1.0872 - val_accuracy: 0.5800\n",
      "Epoch 50/60\n",
      "1200/1200 [==============================] - 59s 49ms/step - loss: 0.9504 - accuracy: 0.6312 - val_loss: 1.0869 - val_accuracy: 0.5694\n",
      "Epoch 51/60\n",
      "1200/1200 [==============================] - 51s 43ms/step - loss: 0.9592 - accuracy: 0.6309 - val_loss: 1.0865 - val_accuracy: 0.5753\n",
      "Epoch 52/60\n",
      "1200/1200 [==============================] - 48s 40ms/step - loss: 0.9463 - accuracy: 0.6323 - val_loss: 1.0852 - val_accuracy: 0.5753\n",
      "Epoch 53/60\n",
      "1200/1200 [==============================] - 49s 41ms/step - loss: 0.9370 - accuracy: 0.6351 - val_loss: 1.0872 - val_accuracy: 0.5772\n",
      "Epoch 54/60\n",
      "1200/1200 [==============================] - 52s 44ms/step - loss: 0.9335 - accuracy: 0.6414 - val_loss: 1.0852 - val_accuracy: 0.5811\n",
      "Epoch 55/60\n",
      "1200/1200 [==============================] - 52s 43ms/step - loss: 0.9337 - accuracy: 0.6386 - val_loss: 1.0858 - val_accuracy: 0.5756\n",
      "Epoch 56/60\n",
      "1200/1200 [==============================] - 55s 46ms/step - loss: 0.9285 - accuracy: 0.6416 - val_loss: 1.0880 - val_accuracy: 0.5786\n",
      "Epoch 57/60\n",
      "1200/1200 [==============================] - 71s 59ms/step - loss: 0.9216 - accuracy: 0.6423 - val_loss: 1.0924 - val_accuracy: 0.5761\n",
      "Epoch 58/60\n",
      "1200/1200 [==============================] - 63s 53ms/step - loss: 0.9203 - accuracy: 0.6488 - val_loss: 1.0917 - val_accuracy: 0.5761\n",
      "Epoch 59/60\n",
      "1200/1200 [==============================] - 47s 39ms/step - loss: 0.9007 - accuracy: 0.6530 - val_loss: 1.0886 - val_accuracy: 0.5714\n",
      "Epoch 60/60\n",
      "1200/1200 [==============================] - 49s 41ms/step - loss: 0.8987 - accuracy: 0.6498 - val_loss: 1.0894 - val_accuracy: 0.5775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d4d372a00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vec_size, input_length=max_length, weights=[word_vector_matrix], trainable=False)) # wagi to sa wektory\n",
    "\n",
    "model.add(Conv1D(64, 8, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "087e1339-75e2-4363-9682-b4372e2643cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 100)          1909700   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 774       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 2,027,722\n",
      "Trainable params: 118,022\n",
      "Non-trainable params: 1,909,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vec_size, input_length=max_length, weights=[word_vector_matrix], trainable=False)) # wagi to sa wektory\n",
    "model.add(LSTM(128, recurrent_dropout=0.5, dropout=0.5))\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "add0ee3f-5c7f-4443-80dd-09b004d69486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "450/450 [==============================] - 112s 245ms/step - loss: 1.7924 - accuracy: 0.1636 - val_loss: 1.7918 - val_accuracy: 0.1714\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 112s 250ms/step - loss: 1.7923 - accuracy: 0.1642 - val_loss: 1.7921 - val_accuracy: 0.1700\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 109s 242ms/step - loss: 1.7922 - accuracy: 0.1611 - val_loss: 1.7926 - val_accuracy: 0.1653\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 113s 252ms/step - loss: 1.7923 - accuracy: 0.1672 - val_loss: 1.7920 - val_accuracy: 0.1600\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 113s 250ms/step - loss: 1.7919 - accuracy: 0.1652 - val_loss: 1.7929 - val_accuracy: 0.1600\n",
      "Epoch 6/30\n",
      "108/450 [======>.......................] - ETA: 1:33 - loss: 1.7924 - accuracy: 0.1716"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3695/1222587057.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/emotion_recognition/env_emo_rec/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/emotion_recognition/env_emo_rec/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/emotion_recognition/env_emo_rec/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/emotion_recognition/env_emo_rec/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/emotion_recognition/env_emo_rec/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Desktop/emotion_recognition/env_emo_rec/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/emotion_recognition/env_emo_rec/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a37fe3ee-5b23-4d4f-9e91-d6e912d4eb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "225/225 [==============================] - 13s 55ms/step - loss: 1.6486 - accuracy: 0.2565 - val_loss: 1.4697 - val_accuracy: 0.3336\n",
      "Epoch 2/5\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 1.3906 - accuracy: 0.3882 - val_loss: 1.2728 - val_accuracy: 0.4653\n",
      "Epoch 3/5\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 1.2275 - accuracy: 0.4725 - val_loss: 1.1771 - val_accuracy: 0.5053\n",
      "Epoch 4/5\n",
      "225/225 [==============================] - 10s 46ms/step - loss: 1.1165 - accuracy: 0.5364 - val_loss: 1.1605 - val_accuracy: 0.5200\n",
      "Epoch 5/5\n",
      "225/225 [==============================] - 11s 48ms/step - loss: 1.0393 - accuracy: 0.5701 - val_loss: 1.1533 - val_accuracy: 0.5472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5af3ca81f0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vec_size, input_length=max_length, weights=[word_vector_matrix], trainable=False)) # wagi to sa wektory\n",
    "\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "    \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "92e79587-dd98-4986-aad7-759908ef6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3c051d7e-8e68-41c2-b1e0-46fde69b722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03753073, 0.01475197, 0.20454566, 0.30121052, 0.23221147,\n",
       "        0.20974961]], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "70cdf36d-c768-450e-b8c6-3e662f3f23bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03753073, 0.01475197, 0.20454566, 0.30121052, 0.23221147,\n",
       "        0.20974961]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cbd0175d-1234-4a73-91fb-1a98c8ef2334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0:1], axis=None, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4f2082c9-bfa6-4bd9-af0f-6ae255ba1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (-pred).argsort()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "06bb412c-5ae1-48fe-b7b4-bbb413d788c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_prediction, secondary_prediction = result[0][0], result[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "927256d1-e575-4bea-98e1-43167be34490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "74439062-c6d2-435b-9a02-e75c068aacb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c9a1d7a6-81fd-4a9f-8685-35234e57b1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test[0:1], axis=None, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f828204-828e-4c79-be74-ac43bfa8d0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c7c2d-dee0-4cea-bc5c-ebc874e36e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "27b22f6d-5942-416b-a874-8a5d8ff6e8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform((np.argmax(y_test[0:1], axis=None, out=None),))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0ef310c6-45a3-4589-8dbf-a26bead3b722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform((np.argmax(pred[0:1], axis=None, out=None),))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ef3c0335-bbae-49b4-86fe-292a01717cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 6), dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec157c93-87b9-4dda-a19d-e3304822ac00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6a4fa607-d377-4d52-a01b-ff5ac7e7c0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998349"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0][np.argmax(pred[0:1], axis=None, out=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b82f1dbe-2f07-40e1-bf49-683fb016b7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5d5f05cd-5c5c-4fc9-b35e-a786c4fa50e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 105,   17,    1,  110,  998,  473,  283,  710,   44, 1291,   18,\n",
       "        555,   24,  177,   47,  555,   21,  163,    4,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dd7306ed-6798-409a-a8fd-cecb8db7df92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3695/2765582958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts(X_test[0:1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3ce4a18d-30c7-4898-abe6-6cabc511c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, token.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1dbd2b66-2968-4e9d-8297-ce1360542405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parent think not best pas final examination secondary school achieve good grade say nothing bad grade would become angry'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = []\n",
    "for i in X_test[0:1][0]:\n",
    "    if i == 0:\n",
    "        break\n",
    "    sentence.append(reverse_word_map[i])\n",
    "' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8369435a-136e-474e-8635-e4aea4914d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence\n",
      "trivia work no computer\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "yeah well sorry not believe kiss sa\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "friend promise would definitely call tell visit not\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "watch series call dynasty detest\n",
      "result\n",
      "disgust\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "sorry suck know ve yay half day though\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "new project go incredibly well not tire today think get monday permanently\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "think haircut isnt bad look yesterday still bad tho\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "alive go notebook all make cry stuff\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "wow shabu himy really feel comfort\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "summer glad appear dollhouse next year still not believe wo not renew tech\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "best friend betray told people secret\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "hahaha omg dude read almost choke haha thanks\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "make boyfriend look different cute no matter\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "hear people talk back\n",
      "result\n",
      "disgust\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "landlord put rent sneaky simply\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "faux goth chick look sorry not go camden like pop punk jimmy eat world\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "yeah dry\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "aww amaze though ve never soco am concert zac hanson give drumstick\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "ooooooooh get pyjama\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "tom tour philippine please would awesome\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "need pizza not get office\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "one friend ask go shop another friend also come along out keep talk felt leave even tried talk seem not listen not pay much attention\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "happy pass go form great relief worry consider large number pupil fail\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "aww poor know u bless\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "saw people beat man seem stranger\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "disgust\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "gcashfollow ve\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "someone tell tonight state old piss\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "disgust\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "girlfriend mention certain girl name girl time back no longer mine say still mine\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "say rol\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "serie fact occur colleague start feel certain necessity get apart not want see anymore\n",
      "result\n",
      "disgust\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "character find rarely enough elaborate much upon anything\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "anger\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "omg much pain duchies\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "friday sun shin quite warm already walk dog freaky hyper\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "happiness\n",
      "----\n",
      "sentence\n",
      "find book start real paper bound journal tonight annoy zit lip make look like herpes\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "truly find astound woman child decide go write entire story man still miss dead son sort timeline grief hope never know like put child ground\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "good plan peg plus like sound money monday\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "ah see cool dude\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "ve never read stop everything read corporate foreign interest behind white house push transfer nuclear technology saudi arabia\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "surprise\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "almost say bless sneeze cat\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "parent not like friend tell stay away\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "happen one best friend take shirt without knowledge not put many day short clothes\n",
      "result\n",
      "disgust\n",
      "primary prediction\n",
      "anger\n",
      "secondary prediction\n",
      "disgust\n",
      "----\n",
      "sentence\n",
      "could buy vespa amount money spent\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "learn tat scenic way din plan go town somehow herd\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "appreciation tweet shah rush khan world big moviestar day ark day\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "michael scofield no dead sorry\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "not well examine\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "choose one nooo betty suppose get end\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "mediterranean kitchen oh well not get right\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "yoyo door nazi refuse entry account no id gutted heard good night tho next time all come prepare\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "dream go evo fest not\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "miss dance friend\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "ya prob dont want no\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "hate get put steroid face\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "anger\n",
      "secondary prediction\n",
      "disgust\n",
      "----\n",
      "sentence\n",
      "oh nice go\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "sooo hot day put ton sunblock jogging still think face burnt though\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "badly examine\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "right however neglect mention young woman gold digger trophy not patriarchy grand\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "disgust\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "father imprison burn house young brother\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "oh lol sorry mind always\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "happiness\n",
      "----\n",
      "sentence\n",
      "like see aunt zaire airport appear impossible go school long time not sure could accompany two day departure tell allow miss school\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "sleep would ve home sooner accidentally kill bambi way home\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "awoke completely freak frantic frenzy go long night\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "earth cake\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "time lose badminton match zambia close badminton championship\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "not one yet hopefully all ponying one soon definitely hit wall\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "om best to show ever\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "elder sister baby girl first girl family year baby boy\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "disgust\n",
      "----\n",
      "sentence\n",
      "no not redirect update post website massage do next item publish next item punish\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "nice natalie taught jameson\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "surprise\n",
      "secondary prediction\n",
      "happiness\n",
      "----\n",
      "sentence\n",
      "person love admired lot die felt empty lonely helpless without support not know\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "sound like kinda day\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "get ready wait cor pick josh movie dinner trailer perhaps back work tomorrow\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "yeah ve notice miss spender closer hold\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "happiness\n",
      "----\n",
      "sentence\n",
      "last summer walk along beach bikini awful man come cycle shout ran fast leg could carry\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "disgust\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "sorry unsociable load stock shop mum making\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "heard name announce radio successful interview admittance medical assistant training course really happy enjoy dance music radio cassette\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "surprise\n",
      "secondary prediction\n",
      "happiness\n",
      "----\n",
      "sentence\n",
      "haha tell ve feel everyday week\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "hitch hike way back town rather drunk drop another town unknown u need urinate wall turn belong military headquarters arrest make pay fine go home foot since late anyone give u lift\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "soo excite pasadena seminar find confirmation email\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "talk past happy hour two friend night camp month ago share feeling notion every hidden anxiety think care happy satisfy\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "many year ago saw film psycho hitchcock first time saw film alone afterwards hardly dare go bed hardly able sleep\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "grovel people\n",
      "result\n",
      "disgust\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "tired work today\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "heh thanks adorable plug cough info cough cough\n",
      "result\n",
      "happiness\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "end relationship year hurt person much\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "follow argument brother break golf club\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "tov saw news feature south african policeman attack group black people whip\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "surprise\n",
      "secondary prediction\n",
      "happiness\n",
      "----\n",
      "sentence\n",
      "scary guy colbert\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "disgust\n",
      "secondary prediction\n",
      "anger\n",
      "----\n",
      "sentence\n",
      "month ago one fellow worker get promotion small promotion recognition involve\n",
      "result\n",
      "anger\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "ran hair first spiderweb full baby spider almost set hair fire get rid almost\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "fear\n",
      "secondary prediction\n",
      "sadness\n",
      "----\n",
      "sentence\n",
      "jordan baby talk wish coulda meet ugh\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "course love he donut shop yours truly\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "movie boyfriend\n",
      "result\n",
      "surprise\n",
      "primary prediction\n",
      "anger\n",
      "secondary prediction\n",
      "disgust\n",
      "----\n",
      "sentence\n",
      "sad find out boot camp late oh well may la day anyway\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "sadness\n",
      "secondary prediction\n",
      "fear\n",
      "----\n",
      "sentence\n",
      "pic wont load twitter\n",
      "result\n",
      "sadness\n",
      "primary prediction\n",
      "happiness\n",
      "secondary prediction\n",
      "surprise\n",
      "----\n",
      "sentence\n",
      "failure ate char view pao think skip dinner go along non existent diet\n",
      "result\n",
      "fear\n",
      "primary prediction\n",
      "surprise\n",
      "secondary prediction\n",
      "happiness\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(y_test)+1):\n",
    "for i in range(200):\n",
    "    pred = model.predict(X_test[i:i+1])\n",
    "    another_pred = (-pred).argsort()[:2]\n",
    "    pred = le.inverse_transform((np.argmax(pred, axis=None, out=None),))[0]\n",
    "    result = le.inverse_transform((np.argmax(y_test[i:i+1], axis=None, out=None),))[0]\n",
    "    prim_pred = le.inverse_transform((another_pred[0][0],))[0]\n",
    "    sec_pred = le.inverse_transform((another_pred[0][1],))[0]\n",
    "    if pred != result:\n",
    "        sentence = []\n",
    "        for a in X_test[i:i+1][0]:\n",
    "            if a == 0:\n",
    "                break\n",
    "            sentence.append(reverse_word_map[a])\n",
    "        classified_sentence = ' '.join(sentence)\n",
    "        print(\"sentence\")\n",
    "        print(classified_sentence)\n",
    "        print(\"result\")\n",
    "        print(result)\n",
    "        print(\"prediction\")\n",
    "        print(pred)\n",
    "        print(\"primary prediction\")\n",
    "        print(prim_pred)\n",
    "        print(\"secondary prediction\")\n",
    "        print(sec_pred)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b925bebd-b8bd-460a-b1b6-927d90153d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform((np.argmax(pred[0:1], axis=None, out=None),))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6716321b-bd65-4e51-a932-c5c300aa845f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'surprise'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "08b75516-c572-4c0c-90fb-681954f13bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "450/450 [==============================] - 12s 25ms/step - loss: 1.8033 - accuracy: 0.1981 - val_loss: 1.7596 - val_accuracy: 0.2367\n",
      "Epoch 2/60\n",
      "450/450 [==============================] - 11s 24ms/step - loss: 1.7447 - accuracy: 0.2418 - val_loss: 1.6967 - val_accuracy: 0.2622\n",
      "Epoch 3/60\n",
      "450/450 [==============================] - 11s 24ms/step - loss: 1.6735 - accuracy: 0.2719 - val_loss: 1.6112 - val_accuracy: 0.2972\n",
      "Epoch 4/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.5909 - accuracy: 0.3079 - val_loss: 1.5329 - val_accuracy: 0.3483\n",
      "Epoch 5/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.5151 - accuracy: 0.3475 - val_loss: 1.4525 - val_accuracy: 0.3886\n",
      "Epoch 6/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.4500 - accuracy: 0.3832 - val_loss: 1.3802 - val_accuracy: 0.4317\n",
      "Epoch 7/60\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.3755 - accuracy: 0.4306 - val_loss: 1.3165 - val_accuracy: 0.4781\n",
      "Epoch 8/60\n",
      "450/450 [==============================] - 13s 28ms/step - loss: 1.3224 - accuracy: 0.4548 - val_loss: 1.2744 - val_accuracy: 0.5042\n",
      "Epoch 9/60\n",
      "450/450 [==============================] - 12s 27ms/step - loss: 1.2844 - accuracy: 0.4727 - val_loss: 1.2354 - val_accuracy: 0.5264\n",
      "Epoch 10/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.2403 - accuracy: 0.4923 - val_loss: 1.2176 - val_accuracy: 0.5231\n",
      "Epoch 11/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.2081 - accuracy: 0.5071 - val_loss: 1.1870 - val_accuracy: 0.5358\n",
      "Epoch 12/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.1821 - accuracy: 0.5252 - val_loss: 1.1638 - val_accuracy: 0.5469\n",
      "Epoch 13/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.1549 - accuracy: 0.5364 - val_loss: 1.1457 - val_accuracy: 0.5522\n",
      "Epoch 14/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.1212 - accuracy: 0.5477 - val_loss: 1.1303 - val_accuracy: 0.5567\n",
      "Epoch 15/60\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0992 - accuracy: 0.5549 - val_loss: 1.1194 - val_accuracy: 0.5647\n",
      "Epoch 16/60\n",
      "450/450 [==============================] - 11s 26ms/step - loss: 1.0731 - accuracy: 0.5719 - val_loss: 1.1094 - val_accuracy: 0.5636\n",
      "Epoch 17/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.0531 - accuracy: 0.5771 - val_loss: 1.0976 - val_accuracy: 0.5681\n",
      "Epoch 18/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 1.0354 - accuracy: 0.5891 - val_loss: 1.0923 - val_accuracy: 0.5717\n",
      "Epoch 19/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 1.0174 - accuracy: 0.5983 - val_loss: 1.0856 - val_accuracy: 0.5725\n",
      "Epoch 20/60\n",
      "450/450 [==============================] - 12s 27ms/step - loss: 0.9948 - accuracy: 0.6072 - val_loss: 1.0816 - val_accuracy: 0.5706\n",
      "Epoch 21/60\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9762 - accuracy: 0.6175 - val_loss: 1.0785 - val_accuracy: 0.5819\n",
      "Epoch 22/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 0.9635 - accuracy: 0.6183 - val_loss: 1.0771 - val_accuracy: 0.5783\n",
      "Epoch 23/60\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9436 - accuracy: 0.6237 - val_loss: 1.0742 - val_accuracy: 0.5803\n",
      "Epoch 24/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 0.9258 - accuracy: 0.6347 - val_loss: 1.0865 - val_accuracy: 0.5828\n",
      "Epoch 25/60\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9182 - accuracy: 0.6391 - val_loss: 1.0782 - val_accuracy: 0.5822\n",
      "Epoch 26/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 0.9004 - accuracy: 0.6476 - val_loss: 1.0784 - val_accuracy: 0.5819\n",
      "Epoch 27/60\n",
      "450/450 [==============================] - 11s 25ms/step - loss: 0.8810 - accuracy: 0.6614 - val_loss: 1.0848 - val_accuracy: 0.5844\n",
      "Epoch 28/60\n",
      "450/450 [==============================] - 19s 41ms/step - loss: 0.8682 - accuracy: 0.6612 - val_loss: 1.0788 - val_accuracy: 0.5797\n",
      "Epoch 29/60\n",
      "450/450 [==============================] - 18s 40ms/step - loss: 0.8517 - accuracy: 0.6698 - val_loss: 1.0816 - val_accuracy: 0.5844\n",
      "Epoch 30/60\n",
      "450/450 [==============================] - 19s 42ms/step - loss: 0.8446 - accuracy: 0.6728 - val_loss: 1.0873 - val_accuracy: 0.5819\n",
      "Epoch 31/60\n",
      "450/450 [==============================] - 19s 42ms/step - loss: 0.8226 - accuracy: 0.6831 - val_loss: 1.0965 - val_accuracy: 0.5797\n",
      "Epoch 32/60\n",
      "450/450 [==============================] - 19s 43ms/step - loss: 0.8060 - accuracy: 0.6842 - val_loss: 1.1137 - val_accuracy: 0.5825\n",
      "Epoch 33/60\n",
      "450/450 [==============================] - 19s 43ms/step - loss: 0.7948 - accuracy: 0.6921 - val_loss: 1.1155 - val_accuracy: 0.5839\n",
      "Epoch 34/60\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 0.7810 - accuracy: 0.6985 - val_loss: 1.1162 - val_accuracy: 0.5797\n",
      "Epoch 35/60\n",
      "450/450 [==============================] - 20s 45ms/step - loss: 0.7706 - accuracy: 0.6996 - val_loss: 1.1074 - val_accuracy: 0.5844\n",
      "Epoch 36/60\n",
      "450/450 [==============================] - 23s 51ms/step - loss: 0.7464 - accuracy: 0.7113 - val_loss: 1.1350 - val_accuracy: 0.5806\n",
      "Epoch 37/60\n",
      "450/450 [==============================] - 20s 45ms/step - loss: 0.7488 - accuracy: 0.7112 - val_loss: 1.1489 - val_accuracy: 0.5811\n",
      "Epoch 38/60\n",
      "450/450 [==============================] - 20s 45ms/step - loss: 0.7229 - accuracy: 0.7193 - val_loss: 1.1423 - val_accuracy: 0.5825\n",
      "Epoch 39/60\n",
      "450/450 [==============================] - 20s 44ms/step - loss: 0.7108 - accuracy: 0.7282 - val_loss: 1.1596 - val_accuracy: 0.5739\n",
      "Epoch 40/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.7015 - accuracy: 0.7262 - val_loss: 1.1725 - val_accuracy: 0.5756\n",
      "Epoch 41/60\n",
      "450/450 [==============================] - 11s 24ms/step - loss: 0.6897 - accuracy: 0.7362 - val_loss: 1.1725 - val_accuracy: 0.5764\n",
      "Epoch 42/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.6683 - accuracy: 0.7443 - val_loss: 1.1779 - val_accuracy: 0.5794\n",
      "Epoch 43/60\n",
      "450/450 [==============================] - 10s 22ms/step - loss: 0.6679 - accuracy: 0.7444 - val_loss: 1.2109 - val_accuracy: 0.5753\n",
      "Epoch 44/60\n",
      "450/450 [==============================] - 11s 24ms/step - loss: 0.6551 - accuracy: 0.7519 - val_loss: 1.2010 - val_accuracy: 0.5811\n",
      "Epoch 45/60\n",
      "450/450 [==============================] - 11s 23ms/step - loss: 0.6422 - accuracy: 0.7526 - val_loss: 1.2259 - val_accuracy: 0.5742\n",
      "Epoch 46/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.6283 - accuracy: 0.7610 - val_loss: 1.2422 - val_accuracy: 0.5767\n",
      "Epoch 47/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.6199 - accuracy: 0.7617 - val_loss: 1.2413 - val_accuracy: 0.5758\n",
      "Epoch 48/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.6096 - accuracy: 0.7677 - val_loss: 1.2736 - val_accuracy: 0.5711\n",
      "Epoch 49/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.5921 - accuracy: 0.7746 - val_loss: 1.2579 - val_accuracy: 0.5714\n",
      "Epoch 50/60\n",
      "450/450 [==============================] - 10s 22ms/step - loss: 0.5855 - accuracy: 0.7788 - val_loss: 1.3115 - val_accuracy: 0.5672\n",
      "Epoch 51/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.5743 - accuracy: 0.7789 - val_loss: 1.2831 - val_accuracy: 0.5703\n",
      "Epoch 52/60\n",
      "450/450 [==============================] - 11s 23ms/step - loss: 0.5646 - accuracy: 0.7835 - val_loss: 1.3236 - val_accuracy: 0.5675\n",
      "Epoch 53/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.5536 - accuracy: 0.7869 - val_loss: 1.3194 - val_accuracy: 0.5728\n",
      "Epoch 54/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.5546 - accuracy: 0.7869 - val_loss: 1.3614 - val_accuracy: 0.5708\n",
      "Epoch 55/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.5356 - accuracy: 0.7931 - val_loss: 1.3673 - val_accuracy: 0.5681\n",
      "Epoch 56/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.5231 - accuracy: 0.8031 - val_loss: 1.3763 - val_accuracy: 0.5733\n",
      "Epoch 57/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.5142 - accuracy: 0.8092 - val_loss: 1.4453 - val_accuracy: 0.5639\n",
      "Epoch 58/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.5002 - accuracy: 0.8095 - val_loss: 1.4303 - val_accuracy: 0.5661\n",
      "Epoch 59/60\n",
      "450/450 [==============================] - 10s 23ms/step - loss: 0.4934 - accuracy: 0.8142 - val_loss: 1.4354 - val_accuracy: 0.5617\n",
      "Epoch 60/60\n",
      "450/450 [==============================] - 11s 24ms/step - loss: 0.4823 - accuracy: 0.8159 - val_loss: 1.4364 - val_accuracy: 0.5650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5af3d6b670>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vec_size, input_length=max_length, weights=[word_vector_matrix], trainable=False)) # wagi to sa wektory\n",
    "\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "    \n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db20d12-f6de-45c9-8de6-c0ef30512f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mgr",
   "language": "python",
   "name": "venv_mgr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
